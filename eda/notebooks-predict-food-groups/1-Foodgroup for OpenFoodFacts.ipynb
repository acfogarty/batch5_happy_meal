{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foodgroup for OpenFoodFacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective** : <br>\n",
    "Predict the foodgroup (12 groups) of a product of Open Food Facts <br>\n",
    "Remark : cannot run without the file `data/openfoodfacts.csv` (85Mo) <br>\n",
    "\n",
    "**Main results** : <br>\n",
    "- using 6 nutrients and random forest : 88.5% of accuracy (87.5% for a simpler model)\n",
    "- using names and naive bayes : 87% of accuracy\n",
    "\n",
    "**Outputs** : <br>\n",
    "- `data/clf_nutrients_rf_groupeAlim_2.sav` (292Mo) : random forest model (88.5% of accuracy)\n",
    "- `data/clf_nutrients_rf_groupeAlim_2_light.sav` (20Mo) : simple random forest model (87.5% of accuracy)\n",
    "- `data/openfoodfacts_groupeAlim_2.csv` (31Mo) : assign a foodgroup to OpenFoodFacts' products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#unidecodeimport unidecode\n",
    "#from collections import Counter\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open Food Facts\n",
    "openfoodfacts = pd.read_csv(\"../../data/openfoodfacts.csv\", sep = ';', \n",
    "                                      encoding = 'UTF-8', dtype = {'EAN': str, 'product_name' : str})\n",
    "openfoodfacts.rename(columns={'saturatedFat_100g':'saturated-fat_100g'}, inplace=True)\n",
    "\n",
    "# Mapping groups\n",
    "mapping_groups = pd.read_csv(\"../../data/mapping_off_ideal.csv\", sep = ';', encoding = 'UTF-8')\n",
    "\n",
    "# Add groups\n",
    "openfoodfacts = openfoodfacts.merge(mapping_groups, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAN</th>\n",
       "      <th>product_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>countries_fr</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>serving_quantity</th>\n",
       "      <th>nutriscore</th>\n",
       "      <th>pnns_groups_1</th>\n",
       "      <th>pnns_groups_2</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>transFat_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>vitaminA_100g</th>\n",
       "      <th>vitaminC_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>score_nutritif_100g</th>\n",
       "      <th>groupeAlim_1</th>\n",
       "      <th>groupeAlim_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000000017</td>\n",
       "      <td>Vitória crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>70.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000000031</td>\n",
       "      <td>Cacao</td>\n",
       "      <td>130 g</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000000123</td>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000000291</td>\n",
       "      <td>Mendiants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000000949</td>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000000000970</td>\n",
       "      <td>Fromage blanc aux myrtilles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000000001001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000000001007</td>\n",
       "      <td>Vainilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0000000001137</td>\n",
       "      <td>Baguette parisien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000000001151</td>\n",
       "      <td>&amp;quot;Baguette Lyonnais&amp;quot;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EAN                   product_name quantity countries_fr  \\\n",
       "0  0000000000017               Vitória crackers      NaN       France   \n",
       "1  0000000000031                          Cacao    130 g       France   \n",
       "2  0000000000123          Sauce Sweety chili 0%      NaN       France   \n",
       "3  0000000000291                      Mendiants      NaN       France   \n",
       "4  0000000000949      Salade de carottes râpées      NaN       France   \n",
       "5  0000000000970    Fromage blanc aux myrtilles      NaN       France   \n",
       "6  0000000001001                            NaN      NaN       France   \n",
       "7  0000000001007                       Vainilla      NaN       France   \n",
       "8  0000000001137              Baguette parisien      NaN       France   \n",
       "9  0000000001151  &quot;Baguette Lyonnais&quot;      NaN       France   \n",
       "\n",
       "  serving_size  serving_quantity nutriscore pnns_groups_1 pnns_groups_2  \\\n",
       "0          NaN               0.0        NaN           NaN           NaN   \n",
       "1          NaN               0.0        NaN           NaN           NaN   \n",
       "2          NaN               0.0        NaN           NaN           NaN   \n",
       "3          NaN               0.0        NaN           NaN           NaN   \n",
       "4          NaN               0.0        NaN           NaN           NaN   \n",
       "5          NaN               0.0        NaN           NaN           NaN   \n",
       "6          NaN               NaN        NaN           NaN           NaN   \n",
       "7          NaN               0.0        NaN           NaN           NaN   \n",
       "8          NaN               0.0        NaN           NaN           NaN   \n",
       "9          NaN               0.0        NaN           NaN           NaN   \n",
       "\n",
       "  categories_tags  energy_100g  carbohydrates_100g  fat_100g  \\\n",
       "0             NaN       1569.0                70.1       7.0   \n",
       "1             NaN          NaN                 NaN       NaN   \n",
       "2             NaN         88.0                 4.8       0.0   \n",
       "3             NaN          NaN                 NaN       NaN   \n",
       "4             NaN        134.0                 5.3       0.3   \n",
       "5             NaN        540.0                16.3       4.9   \n",
       "6             NaN          NaN                 NaN       NaN   \n",
       "7             NaN          NaN                 NaN       NaN   \n",
       "8             NaN        929.0                38.4       3.3   \n",
       "9             NaN       1213.0                41.0       9.4   \n",
       "\n",
       "   saturated-fat_100g  transFat_100g  sugars_100g  fiber_100g  proteins_100g  \\\n",
       "0                3.08            NaN         15.0         NaN            7.8   \n",
       "1                 NaN            NaN          NaN         NaN            NaN   \n",
       "2                0.00            NaN          0.4         NaN            0.2   \n",
       "3                 NaN            NaN          NaN         NaN            NaN   \n",
       "4                0.10            NaN          3.9         NaN            0.9   \n",
       "5                3.10            NaN         16.3         NaN            4.4   \n",
       "6                 NaN            NaN          NaN         NaN            NaN   \n",
       "7                 NaN            NaN          NaN         NaN            NaN   \n",
       "8                2.10            NaN          1.8         NaN           11.7   \n",
       "9                4.50            NaN          2.0         NaN           12.5   \n",
       "\n",
       "   salt_100g  vitaminA_100g  vitaminC_100g  calcium_100g  iron_100g  \\\n",
       "0      1.400            NaN            NaN           NaN        NaN   \n",
       "1        NaN            NaN            NaN           NaN        NaN   \n",
       "2      2.040            NaN            NaN           NaN        NaN   \n",
       "3        NaN            NaN            NaN           NaN        NaN   \n",
       "4      0.420            NaN            NaN           NaN        NaN   \n",
       "5      0.250            NaN            NaN           NaN        NaN   \n",
       "6        NaN            NaN            NaN           NaN        NaN   \n",
       "7        NaN            NaN            NaN           NaN        NaN   \n",
       "8      0.678            NaN            NaN           NaN        NaN   \n",
       "9      0.900            NaN            NaN           NaN        NaN   \n",
       "\n",
       "   score_nutritif_100g groupeAlim_1 groupeAlim_2  \n",
       "0                  NaN          NaN          NaN  \n",
       "1                  NaN          NaN          NaN  \n",
       "2                  NaN          NaN          NaN  \n",
       "3                  NaN          NaN          NaN  \n",
       "4                  NaN          NaN          NaN  \n",
       "5                  NaN          NaN          NaN  \n",
       "6                  NaN          NaN          NaN  \n",
       "7                  NaN          NaN          NaN  \n",
       "8                  NaN          NaN          NaN  \n",
       "9                  NaN          NaN          NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openfoodfacts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose between pnns_groups_1, pnns_groups_2, (groupeAlim_1), groupeAlim_2\n",
    "# This is the name of the target variable\n",
    "level_groupe = \"groupeAlim_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110274, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keeping observations where the food group is valid and removing easy outliers\n",
    "openfoodfacts_ml_nutrients = openfoodfacts[pd.notnull(openfoodfacts[level_groupe])] #has the food group\n",
    "\n",
    "# With valid nutrients\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['salt_100g'] <= 100]\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['sugars_100g'] <= 100]\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['carbohydrates_100g'] <= 100]\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['fat_100g'] <= 100]\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['proteins_100g'] <= 100]\n",
    "openfoodfacts_ml_nutrients = openfoodfacts_ml_nutrients[openfoodfacts_ml_nutrients['saturated-fat_100g'] <= 100]\n",
    "\n",
    "openfoodfacts_ml_nutrients.shape #110274 x 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the 677830 observations of the database of Open Food Facts, only 110274 are useful for this methodology.\n",
      "       \tIn the training dataset, there are 88219 observations.\n",
      "\tIn the test dataset, there are 22055 observations.\n"
     ]
    }
   ],
   "source": [
    "# Train and test sets\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(openfoodfacts_ml_nutrients[['salt_100g', 'sugars_100g',\n",
    "                                                                                    'carbohydrates_100g', 'fat_100g',\n",
    "                                                                                    'proteins_100g', 'saturated-fat_100g']],\n",
    "                                                                    openfoodfacts_ml_nutrients[level_groupe],\n",
    "                                                                    test_size = 0.2)\n",
    "\n",
    "print(\"Among the %.0f observations of the database of Open Food Facts, only %.0f are useful for this methodology.\\n \\\n",
    "      \\tIn the training dataset, there are %.0f observations.\\n\\tIn the test dataset, there are %.0f observations.\" % \n",
    "      (openfoodfacts.shape[0], openfoodfacts_ml_nutrients.shape[0], train_x.shape[0], test_x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning step ...\n",
      "Prediction step ...\n",
      "groupeAlim_2 - Accuracy of the random forest model : 88.69%\n"
     ]
    }
   ],
   "source": [
    "# Learning \n",
    "print('Learning step ...')\n",
    "clf_nutrients_rf = RandomForestClassifier(random_state = 50, n_jobs = -1,\n",
    "                                          max_features = 2, criterion = 'entropy', n_estimators = 100,\n",
    "                                          max_depth = 40)\n",
    "clf_nutrients_rf.fit(train_x, train_y)\n",
    "\n",
    "# Prediction\n",
    "print('Prediction step ...')\n",
    "predictions = clf_nutrients_rf.predict(test_x)\n",
    "accuracy_model = accuracy_score(y_true = test_y, y_pred = predictions)\n",
    "print('%s - Accuracy of the random forest model : %.2f%%' % (level_groupe, 100 * accuracy_model)) \n",
    "#pnns_groups_2 : 82.0%\n",
    "#pnns_groups_1 : 88.7%, \n",
    "#groupeAlim_2 : 88.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupeAlim_2 - Accuracy of the light random forest model : 87.90%\n"
     ]
    }
   ],
   "source": [
    "# Learning simpler and lighter model\n",
    "# This model requires less memory to be stored and is quicker to compute\n",
    "\n",
    "clf_nutrients_rf_light = RandomForestClassifier(random_state = 50, n_jobs = -1,\n",
    "                                          max_features = 3, criterion = 'entropy', n_estimators = 15,\n",
    "                                          max_depth = 20, min_samples_split = 4, min_samples_leaf = 4)\n",
    "clf_nutrients_rf_light.fit(train_x, train_y)\n",
    "\n",
    "# Prediction\n",
    "predictions_light = clf_nutrients_rf_light.predict(test_x)\n",
    "accuracy_model_light = accuracy_score(y_true = test_y, y_pred = predictions_light)\n",
    "print('%s - Accuracy of the light random forest model : %.2f%%' % (level_groupe, 100 * accuracy_model_light)) \n",
    "# groupeAlim_2 :87.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's optimize the hyperparameters ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for 10\n",
      "Estimation for 25\n",
      "Estimation for 50\n",
      "Estimation for 100\n",
      "Estimation for 200\n",
      "Estimation for 300\n",
      "   n_estimator  training_accuracy  validation_accuracy\n",
      "0           10              98.65                87.32\n",
      "1           25              99.16                88.10\n",
      "2           50              99.25                88.37\n",
      "3          100              99.28                88.40\n",
      "4          200              99.28                88.55\n",
      "5          300              99.28                88.59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKRGIiMScEoGISMwpEYiIxNz/BzvOhJhcqoIVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization for n_estimators\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "#list_n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)]\n",
    "list_n_estimators = [10, 25, 50, 100, 200, 300]\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_n_estimators : \n",
    "    \n",
    "    print(\"Estimation for %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(n_estimators=hyp, n_jobs=-1)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'n_estimator' : list_n_estimators,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)\n",
    "\n",
    "# Plotting the results\n",
    "line1, = plt.plot(list_n_estimators, training_accuracy, 'b', label=\"Training accuracy\")\n",
    "line2, = plt.plot(list_n_estimators, valid_accuracy, 'r', label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for max_features = 1\n",
      "Estimation for max_features = 2\n",
      "Estimation for max_features = 3\n",
      "Estimation for max_features = 4\n",
      "Estimation for max_features = 5\n",
      "   max_features  training_accuracy  validation_accuracy\n",
      "0             1              99.24                88.29\n",
      "1             2              99.25                88.21\n",
      "2             3              99.23                88.53\n",
      "3             4              99.23                88.39\n",
      "4             5              99.24                88.33\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization for max_features\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "list_max_features = [1,2,3,4,5]\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_max_features : \n",
    "    \n",
    "    print(\"Estimation for max_features = %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(max_features=hyp, n_jobs=-1, n_estimators = 50)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'max_features' : list_max_features,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)\n",
    "\n",
    "# Plotting the results\n",
    "line1, = plt.plot(list_max_features, training_accuracy, 'b', label=\"Training accuracy\")\n",
    "line2, = plt.plot(list_max_features, valid_accuracy, 'r', label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max_features')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for max_depth = 10\n",
      "Estimation for max_depth = 20\n",
      "Estimation for max_depth = 30\n",
      "Estimation for max_depth = 40\n",
      "Estimation for max_depth = 50\n",
      "Estimation for max_depth = 60\n",
      "Estimation for max_depth = None\n",
      "   max_depth  training_accuracy  validation_accuracy\n",
      "0       10.0              86.29                84.83\n",
      "1       20.0              98.24                88.17\n",
      "2       30.0              99.22                88.17\n",
      "3       40.0              99.26                88.17\n",
      "4       50.0              99.26                88.14\n",
      "5       60.0              99.26                88.19\n",
      "6        NaN              99.26                88.14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization for max_depth\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "list_max_depth = [int(x) for x in np.linspace(10, 60, num = 6)]\n",
    "list_max_depth.append(None)\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_max_depth : \n",
    "    \n",
    "    print(\"Estimation for max_depth = %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(max_depth=hyp, n_jobs=-1, n_estimators = 50)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'max_depth' : list_max_depth,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)\n",
    "\n",
    "# Plotting the results\n",
    "line1, = plt.plot(list_max_depth, training_accuracy, 'b', label=\"Training accuracy\")\n",
    "line2, = plt.plot(list_max_depth, valid_accuracy, 'r', label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max_depth')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for min_samples_split = 2\n",
      "Estimation for min_samples_split = 4\n",
      "Estimation for min_samples_split = 6\n",
      "Estimation for min_samples_split = 8\n",
      "Estimation for min_samples_split = 10\n",
      "Estimation for min_samples_split = 12\n",
      "Estimation for min_samples_split = 14\n",
      "Estimation for min_samples_split = 16\n",
      "   min_samples_split  training_accuracy  validation_accuracy\n",
      "0                  2              99.28                88.32\n",
      "1                  4              98.23                88.34\n",
      "2                  6              96.68                88.22\n",
      "3                  8              95.45                88.13\n",
      "4                 10              94.38                88.05\n",
      "5                 12              93.60                87.90\n",
      "6                 14              92.96                87.99\n",
      "7                 16              92.40                87.80\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization for min_samples_split\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "list_min_samples_split = [2,4,6,8,10,12,14,16]\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_min_samples_split : \n",
    "    \n",
    "    print(\"Estimation for min_samples_split = %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(min_samples_split=hyp, n_jobs=-1, n_estimators = 50)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'min_samples_split' : list_min_samples_split,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)\n",
    "\n",
    "# Plotting the results\n",
    "line1, = plt.plot(list_min_samples_split, training_accuracy, 'b', label=\"Training accuracy\")\n",
    "line2, = plt.plot(list_min_samples_split, valid_accuracy, 'r', label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for min_samples_leaf = 1\n",
      "Estimation for min_samples_leaf = 3\n",
      "Estimation for min_samples_leaf = 5\n",
      "Estimation for min_samples_leaf = 7\n",
      "Estimation for min_samples_leaf = 9\n",
      "Estimation for min_samples_leaf = 11\n",
      "Estimation for min_samples_leaf = 13\n",
      "Estimation for min_samples_leaf = 15\n",
      "   min_samples_leaf  training_accuracy  validation_accuracy\n",
      "0                 1              99.25                88.04\n",
      "1                 3              94.12                87.93\n",
      "2                 5              91.85                87.54\n",
      "3                 7              90.45                87.24\n",
      "4                 9              89.51                87.00\n",
      "5                11              88.88                86.73\n",
      "6                13              88.45                86.50\n",
      "7                15              87.96                86.36\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMMjNuUsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization for min_samples_leaf\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "list_min_samples_leaf = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_min_samples_leaf : \n",
    "    \n",
    "    print(\"Estimation for min_samples_leaf = %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(min_samples_leaf=hyp, n_jobs=-1, n_estimators = 50)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'min_samples_leaf' : list_min_samples_leaf,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)\n",
    "\n",
    "# Plotting the results\n",
    "line1, = plt.plot(list_min_samples_leaf, training_accuracy, 'b', label=\"Training accuracy\")\n",
    "line2, = plt.plot(list_min_samples_leaf, valid_accuracy, 'r', label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation for criterion = gini\n",
      "Estimation for criterion = entropy\n",
      "  criterion  training_accuracy  validation_accuracy\n",
      "0      gini              99.28                88.01\n",
      "1   entropy              99.28                88.11\n"
     ]
    }
   ],
   "source": [
    "# Optimization for criterion\n",
    "training_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "# Hyperparameter's range\n",
    "list_criterion = ['gini', 'entropy']\n",
    "\n",
    "# Training and validation sets\n",
    "training_x, valid_x, training_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "for hyp in list_criterion : \n",
    "    \n",
    "    print(\"Estimation for criterion = %s\" % hyp)\n",
    "     \n",
    "    # Fit the data\n",
    "    rf = RandomForestClassifier(criterion=hyp, n_jobs=-1, n_estimators = 50)\n",
    "    rf.fit(training_x, training_y)\n",
    "\n",
    "    # Prediction\n",
    "    training_pred = rf.predict(training_x)\n",
    "    valid_pred = rf.predict(valid_x)\n",
    "\n",
    "    # Accuracy\n",
    "    training_acc = 100 * accuracy_score(y_true = training_y, y_pred = training_pred)\n",
    "    valid_acc = 100 * accuracy_score(y_true = valid_y, y_pred = valid_pred)\n",
    "        \n",
    "    training_accuracy.append(training_acc)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    \n",
    "results = pd.DataFrame({'criterion' : list_criterion,\n",
    "            'training_accuracy' : np.round(training_accuracy, 2),\n",
    "            'validation_accuracy' : np.round(valid_accuracy, 2)})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to these 1-dimensional analysis, one gets the following intuition : \n",
    "- n_estimators : the greater, the better. Over 50, the gain is not very interesting ;\n",
    "- max_features : 2 or 3 seem correct ;\n",
    "- max_depth : 20 seems to be a correct threshold ;\n",
    "- min_samples_split : best performance for 2-8 ;\n",
    "- min_samples_leaf : the lower, the better ;\n",
    "- criterion : not a big difference between gini and entropy\n",
    "\n",
    "Let's try a random grid search : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimization with a random grid search\n",
    "\n",
    "# Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 10)]\n",
    "#n_estimators = [5, 10, 15]\n",
    "n_estimators = [40, 50, 100, 200]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [2,3]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 20, 30]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [4, 8, 16]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 8]\n",
    "# Criterion\n",
    "criterion = ['entropy', 'gini']\n",
    "\n",
    "# Create the random grid\n",
    "#random_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    "#               'max_depth': max_depth,\n",
    "#               'min_samples_split': min_samples_split,\n",
    "#               'min_samples_leaf': min_samples_leaf,\n",
    "#               'criterion' : criterion}\n",
    "random_grid = {'n_estimators': [100],\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'criterion' : criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'max_depth': 20, 'criterion': 'entropy', 'min_samples_leaf': 1, 'max_features': 2, 'n_estimators': 100}\n",
      "groupeAlim_2 - Accuracy of the random forest model : 88.61%\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "clf_nutrients_rf_to_optimize = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using cv fold cross validation, \n",
    "# search across different combinations, and use all available cores\n",
    "random_grid_search = model_selection.RandomizedSearchCV(estimator = clf_nutrients_rf_to_optimize, \n",
    "                                                           param_distributions = random_grid,\n",
    "                                                           n_iter = 12, cv = 5, \n",
    "                                                           verbose=2, random_state=214, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Evaluate the best hyperparameters\n",
    "print(random_grid_search.best_params_)\n",
    "\n",
    "# Prediction\n",
    "prediction = random_grid_search.predict(test_x)\n",
    "accuracy_model = accuracy_score(y_true = test_y, y_pred = prediction)\n",
    "print('%s - Accuracy of the random forest model : %.2f%%' % (level_groupe, 100 * accuracy_model))\n",
    "\n",
    "# pnns_groups_2 : 82.05% with {'n_estimators': 300, 'criterion': 'entropy', 'max_features': 2}\n",
    "# pnns_groups_1 : 88.79% with {'n_estimators': 200, 'criterion': 'entropy', 'max_features': 2}\n",
    "# groupeAlim_2 : 88.47% with {'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'max_features': 2, 'n_estimators': 100, 'max_depth': 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.048444</td>\n",
       "      <td>1.441499</td>\n",
       "      <td>0.882701</td>\n",
       "      <td>0.989934</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 20, 'cri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>0.990435</td>\n",
       "      <td>0.877373</td>\n",
       "      <td>0.990067</td>\n",
       "      <td>0.883990</td>\n",
       "      <td>0.989670</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.884624</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>1.765694</td>\n",
       "      <td>0.138146</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.533584</td>\n",
       "      <td>1.784503</td>\n",
       "      <td>0.882372</td>\n",
       "      <td>0.992893</td>\n",
       "      <td>entropy</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 30, 'cri...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.882990</td>\n",
       "      <td>0.993085</td>\n",
       "      <td>0.877543</td>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.884387</td>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.883793</td>\n",
       "      <td>0.992930</td>\n",
       "      <td>0.883150</td>\n",
       "      <td>0.992845</td>\n",
       "      <td>9.176633</td>\n",
       "      <td>0.501063</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.366794</td>\n",
       "      <td>2.046470</td>\n",
       "      <td>0.881964</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>entropy</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 30, 'cri...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.881800</td>\n",
       "      <td>0.993099</td>\n",
       "      <td>0.877713</td>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.885123</td>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.882886</td>\n",
       "      <td>0.992930</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>0.992803</td>\n",
       "      <td>6.908306</td>\n",
       "      <td>0.477994</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32.772967</td>\n",
       "      <td>1.637807</td>\n",
       "      <td>0.881783</td>\n",
       "      <td>0.992666</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 30, 'cri...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883046</td>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.877033</td>\n",
       "      <td>0.992632</td>\n",
       "      <td>0.883876</td>\n",
       "      <td>0.992561</td>\n",
       "      <td>0.882773</td>\n",
       "      <td>0.992646</td>\n",
       "      <td>0.882186</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>1.105954</td>\n",
       "      <td>0.290947</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.026631</td>\n",
       "      <td>1.262277</td>\n",
       "      <td>0.881681</td>\n",
       "      <td>0.990351</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 20, 'cri...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.880723</td>\n",
       "      <td>0.990619</td>\n",
       "      <td>0.877600</td>\n",
       "      <td>0.990605</td>\n",
       "      <td>0.884613</td>\n",
       "      <td>0.989699</td>\n",
       "      <td>0.882433</td>\n",
       "      <td>0.990535</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.990295</td>\n",
       "      <td>4.189044</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.733495</td>\n",
       "      <td>1.548227</td>\n",
       "      <td>0.881375</td>\n",
       "      <td>0.983657</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 20, 'cri...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.882196</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.876240</td>\n",
       "      <td>0.983790</td>\n",
       "      <td>0.883196</td>\n",
       "      <td>0.983252</td>\n",
       "      <td>0.882150</td>\n",
       "      <td>0.983819</td>\n",
       "      <td>0.883093</td>\n",
       "      <td>0.983721</td>\n",
       "      <td>0.775491</td>\n",
       "      <td>0.265407</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.522428</td>\n",
       "      <td>1.372935</td>\n",
       "      <td>0.881023</td>\n",
       "      <td>0.992502</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 30, 'cri...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.879873</td>\n",
       "      <td>0.992547</td>\n",
       "      <td>0.876806</td>\n",
       "      <td>0.992547</td>\n",
       "      <td>0.884613</td>\n",
       "      <td>0.992547</td>\n",
       "      <td>0.882206</td>\n",
       "      <td>0.992533</td>\n",
       "      <td>0.881619</td>\n",
       "      <td>0.992335</td>\n",
       "      <td>2.644617</td>\n",
       "      <td>0.192973</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.357578</td>\n",
       "      <td>1.600569</td>\n",
       "      <td>0.880865</td>\n",
       "      <td>0.983649</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 20, 'cri...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.881573</td>\n",
       "      <td>0.983903</td>\n",
       "      <td>0.876126</td>\n",
       "      <td>0.984144</td>\n",
       "      <td>0.882460</td>\n",
       "      <td>0.982657</td>\n",
       "      <td>0.882150</td>\n",
       "      <td>0.983763</td>\n",
       "      <td>0.882016</td>\n",
       "      <td>0.983778</td>\n",
       "      <td>1.166317</td>\n",
       "      <td>0.223857</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.109686</td>\n",
       "      <td>1.084910</td>\n",
       "      <td>0.855496</td>\n",
       "      <td>0.873828</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 10, 'cri...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.859644</td>\n",
       "      <td>0.873815</td>\n",
       "      <td>0.852100</td>\n",
       "      <td>0.873817</td>\n",
       "      <td>0.855823</td>\n",
       "      <td>0.874231</td>\n",
       "      <td>0.857548</td>\n",
       "      <td>0.873091</td>\n",
       "      <td>0.852364</td>\n",
       "      <td>0.874187</td>\n",
       "      <td>3.309407</td>\n",
       "      <td>0.047645</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.178852</td>\n",
       "      <td>1.024876</td>\n",
       "      <td>0.853184</td>\n",
       "      <td>0.870637</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 10, 'cri...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.858114</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.848983</td>\n",
       "      <td>0.872074</td>\n",
       "      <td>0.852649</td>\n",
       "      <td>0.870165</td>\n",
       "      <td>0.855054</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>0.870220</td>\n",
       "      <td>1.378752</td>\n",
       "      <td>0.126746</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.292896</td>\n",
       "      <td>1.325977</td>\n",
       "      <td>0.850384</td>\n",
       "      <td>0.868101</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 10, 'cri...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.854941</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0.845413</td>\n",
       "      <td>0.869282</td>\n",
       "      <td>0.851176</td>\n",
       "      <td>0.867232</td>\n",
       "      <td>0.854713</td>\n",
       "      <td>0.867990</td>\n",
       "      <td>0.845674</td>\n",
       "      <td>0.868392</td>\n",
       "      <td>8.825961</td>\n",
       "      <td>0.232382</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.829726</td>\n",
       "      <td>1.826402</td>\n",
       "      <td>0.848026</td>\n",
       "      <td>0.864329</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 10, 'cri...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.850521</td>\n",
       "      <td>0.862521</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.864876</td>\n",
       "      <td>0.849476</td>\n",
       "      <td>0.865970</td>\n",
       "      <td>0.849442</td>\n",
       "      <td>0.862563</td>\n",
       "      <td>0.847318</td>\n",
       "      <td>0.865715</td>\n",
       "      <td>3.574753</td>\n",
       "      <td>0.416992</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2       42.048444         1.441499         0.882701          0.989934   \n",
       "4       48.533584         1.784503         0.882372          0.992893   \n",
       "5       90.366794         2.046470         0.881964          0.992887   \n",
       "10      32.772967         1.637807         0.881783          0.992666   \n",
       "3       58.026631         1.262277         0.881681          0.990351   \n",
       "8       33.733495         1.548227         0.881375          0.983657   \n",
       "11      41.522428         1.372935         0.881023          0.992502   \n",
       "9       41.357578         1.600569         0.880865          0.983649   \n",
       "1       43.109686         1.084910         0.855496          0.873828   \n",
       "0       28.178852         1.024876         0.853184          0.870637   \n",
       "7       41.292896         1.325977         0.850384          0.868101   \n",
       "6       32.829726         1.826402         0.848026          0.864329   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "2          entropy              20                  2                      1   \n",
       "4          entropy              30                  2                      1   \n",
       "5          entropy              30                  3                      1   \n",
       "10            gini              30                  2                      1   \n",
       "3          entropy              20                  3                      1   \n",
       "8             gini              20                  2                      1   \n",
       "11            gini              30                  3                      1   \n",
       "9             gini              20                  3                      1   \n",
       "1          entropy              10                  3                      1   \n",
       "0          entropy              10                  2                      1   \n",
       "7             gini              10                  3                      1   \n",
       "6             gini              10                  2                      1   \n",
       "\n",
       "   param_min_samples_split param_n_estimators  \\\n",
       "2                        2                100   \n",
       "4                        2                100   \n",
       "5                        2                100   \n",
       "10                       2                100   \n",
       "3                        2                100   \n",
       "8                        2                100   \n",
       "11                       2                100   \n",
       "9                        2                100   \n",
       "1                        2                100   \n",
       "0                        2                100   \n",
       "7                        2                100   \n",
       "6                        2                100   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "2   {'min_samples_split': 2, 'max_depth': 20, 'cri...                1   \n",
       "4   {'min_samples_split': 2, 'max_depth': 30, 'cri...                2   \n",
       "5   {'min_samples_split': 2, 'max_depth': 30, 'cri...                3   \n",
       "10  {'min_samples_split': 2, 'max_depth': 30, 'cri...                4   \n",
       "3   {'min_samples_split': 2, 'max_depth': 20, 'cri...                5   \n",
       "8   {'min_samples_split': 2, 'max_depth': 20, 'cri...                6   \n",
       "11  {'min_samples_split': 2, 'max_depth': 30, 'cri...                7   \n",
       "9   {'min_samples_split': 2, 'max_depth': 20, 'cri...                8   \n",
       "1   {'min_samples_split': 2, 'max_depth': 10, 'cri...                9   \n",
       "0   {'min_samples_split': 2, 'max_depth': 10, 'cri...               10   \n",
       "7   {'min_samples_split': 2, 'max_depth': 10, 'cri...               11   \n",
       "6   {'min_samples_split': 2, 'max_depth': 10, 'cri...               12   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "2            0.883500            0.990435           0.877373   \n",
       "4            0.882990            0.993085           0.877543   \n",
       "5            0.881800            0.993099           0.877713   \n",
       "10           0.883046            0.992802           0.877033   \n",
       "3            0.880723            0.990619           0.877600   \n",
       "8            0.882196            0.983704           0.876240   \n",
       "11           0.879873            0.992547           0.876806   \n",
       "9            0.881573            0.983903           0.876126   \n",
       "1            0.859644            0.873815           0.852100   \n",
       "0            0.858114            0.870428           0.848983   \n",
       "7            0.854941            0.867609           0.845413   \n",
       "6            0.850521            0.862521           0.843373   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "2             0.990067           0.883990            0.989670   \n",
       "4             0.992802           0.884387            0.992802   \n",
       "5             0.992802           0.885123            0.992802   \n",
       "10            0.992632           0.883876            0.992561   \n",
       "3             0.990605           0.884613            0.989699   \n",
       "8             0.983790           0.883196            0.983252   \n",
       "11            0.992547           0.884613            0.992547   \n",
       "9             0.984144           0.882460            0.982657   \n",
       "1             0.873817           0.855823            0.874231   \n",
       "0             0.872074           0.852649            0.870165   \n",
       "7             0.869282           0.851176            0.867232   \n",
       "6             0.864876           0.849476            0.865970   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "2            0.884020            0.989898           0.884624   \n",
       "4            0.883793            0.992930           0.883150   \n",
       "5            0.882886            0.992930           0.882300   \n",
       "10           0.882773            0.992646           0.882186   \n",
       "3            0.882433            0.990535           0.883037   \n",
       "8            0.882150            0.983819           0.883093   \n",
       "11           0.882206            0.992533           0.881619   \n",
       "9            0.882150            0.983763           0.882016   \n",
       "1            0.857548            0.873091           0.852364   \n",
       "0            0.855054            0.870300           0.851117   \n",
       "7            0.854713            0.867990           0.845674   \n",
       "6            0.849442            0.862563           0.847318   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "2             0.989601      1.765694        0.138146        0.002688   \n",
       "4             0.992845      9.176633        0.501063        0.002465   \n",
       "5             0.992803      6.908306        0.477994        0.002410   \n",
       "10            0.992689      1.105954        0.290947        0.002437   \n",
       "3             0.990295      4.189044        0.066066        0.002391   \n",
       "8             0.983721      0.775491        0.265407        0.002605   \n",
       "11            0.992335      2.644617        0.192973        0.002598   \n",
       "9             0.983778      1.166317        0.223857        0.002387   \n",
       "1             0.874187      3.309407        0.047645        0.002928   \n",
       "0             0.870220      1.378752        0.126746        0.003163   \n",
       "7             0.868392      8.825961        0.232382        0.004172   \n",
       "6             0.865715      3.574753        0.416992        0.002549   \n",
       "\n",
       "    std_train_score  \n",
       "2          0.000300  \n",
       "4          0.000107  \n",
       "5          0.000117  \n",
       "10         0.000079  \n",
       "3          0.000346  \n",
       "8          0.000207  \n",
       "11         0.000083  \n",
       "9          0.000515  \n",
       "1          0.000409  \n",
       "0          0.000724  \n",
       "7          0.000706  \n",
       "6          0.001503  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(random_grid_search.cv_results_)\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning \n",
    "#clf_nutrients_svc = svm.SVC(random_state = 0)\n",
    "#clf_nutrients_svc.fit(train_x, train_y)\n",
    "\n",
    "# Prediction\n",
    "#prediction = clf_nutrients_svc.predict(test_x)\n",
    "#accuracy_model = accuracy_score(y_true = test_y, y_pred = prediction)\n",
    "#print('Accuracy of the SVC model : %.2f%%' % (100 * accuracy_model)) #pnns_groups_1 : 85% vs 88% for rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning \n",
    "#clf_nutrients_gbc = GradientBoostingClassifier(random_state = 0)\n",
    "#clf_nutrients_gbc.fit(train_x, train_y)\n",
    "\n",
    "# Prediction\n",
    "#prediction = clf_nutrients_gbc.predict(test_x)\n",
    "#accuracy_model = accuracy_score(y_true = test_y, y_pred = prediction)\n",
    "#print('Accuracy of the gradient boosting model : %.2f%%' % (100 * accuracy_model)) #pnns_groups_2 : 77% vs 82% for rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133003, 26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keeping observations where the food group is valid and with a name\n",
    "openfoodfacts_ml_names = openfoodfacts[pd.notnull(openfoodfacts[level_groupe])] #has the food group\n",
    "\n",
    "# With a valid name\n",
    "openfoodfacts_ml_names = openfoodfacts_ml_names[pd.notnull(openfoodfacts_ml_names['product_name'])]\n",
    "\n",
    "openfoodfacts_ml_names.shape #133303 x 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the 677830 observations of the database of Open Food Facts, only 133003 are useful for this methodology.\n",
      "       \tIn the training dataset, there are 106402 observations.\n",
      "\tIn the test dataset, there are 26601 observation\n"
     ]
    }
   ],
   "source": [
    "# Training and test sets\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(openfoodfacts_ml_names['product_name'],\n",
    "                                                                    openfoodfacts_ml_names[level_groupe],\n",
    "                                                                    test_size = 0.2)\n",
    "\n",
    "print(\"Among the %.0f observations of the database of Open Food Facts, only %.0f are useful for this methodology.\\n \\\n",
    "      \\tIn the training dataset, there are %.0f observations.\\n\\tIn the test dataset, there are %.0f observation\" % \n",
    "      (openfoodfacts.shape[0], openfoodfacts_ml_names.shape[0], train_x.shape[0], test_x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the naive bayes model : 86.77%\n"
     ]
    }
   ],
   "source": [
    "# Firstly, let's create a pipeline which will contains all hyper-parameters\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(stop_words = set(stopwords.words('french')), \n",
    "                                         min_df = 1,\n",
    "                                         ngram_range = (1,3))),\n",
    "    ('naive_bayes', naive_bayes.MultinomialNB(alpha = 1e-3))\n",
    "    ])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(train_x, train_y)\n",
    "\n",
    "# Predict the labels on validation dataset\n",
    "prediction = pipeline.predict(test_x)\n",
    "accuracy_model = accuracy_score(y_true = test_y, y_pred = prediction)\n",
    "print('Accuracy of the naive bayes model : %.2f%%' % (100 * accuracy_model)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's optimize hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimization with a random grid search\n",
    "\n",
    "# Alpha smoothing parameters\n",
    "alpha = [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "#N-grams\n",
    "ngram_range = [(1,1), (1,2), (1,3)]\n",
    "\n",
    "# Minimal number of occurences\n",
    "min_df = [1,2,3]\n",
    "\n",
    "# Create the random grid\n",
    "# Note : follow the notation : MODEL__PARAM ! \n",
    "random_grid = {'naive_bayes__alpha': alpha,\n",
    "               'count_vectorizer__ngram_range' : ngram_range,\n",
    "               'count_vectorizer__min_df': min_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vectorizer__ngram_range': (1, 2), 'naive_bayes__alpha': 0.1, 'count_vectorizer__min_df': 1}\n",
      "Accuracy of the best naive bayes model : 86.95%\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Firstly, let's create a pipeline which will contains all hyper-parameters\n",
    "pipeline_to_optimize = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(stop_words = set(stopwords.words('french')))),\n",
    "    ('naive_bayes', naive_bayes.MultinomialNB())\n",
    "    ])\n",
    "\n",
    "# All parameters to tune =)\n",
    "# pipeline_to_optimize.get_params().keys()\n",
    "\n",
    "# Random search of parameters, using cv fold cross validation, \n",
    "# search across different combinations, and use all available cores\n",
    "random_grid_search = model_selection.RandomizedSearchCV(estimator = pipeline_to_optimize, \n",
    "                                                   param_distributions = random_grid,\n",
    "                                                   n_iter = 25, cv = 5,\n",
    "                                                   verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Evaluate the best hyperparameters\n",
    "print(random_grid_search.best_params_)\n",
    "\n",
    "# Prediction\n",
    "predictions = random_grid_search.predict(test_x)\n",
    "accuracy_model = accuracy_score(y_true = test_y, y_pred = predictions)\n",
    "print('Accuracy of the best naive bayes model : %.2f%%' % (100 * accuracy_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_count_vectorizer__min_df</th>\n",
       "      <th>param_count_vectorizer__ngram_range</th>\n",
       "      <th>param_naive_bayes__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.340238</td>\n",
       "      <td>1.058096</td>\n",
       "      <td>0.865144</td>\n",
       "      <td>0.955064</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866479</td>\n",
       "      <td>0.955097</td>\n",
       "      <td>0.863942</td>\n",
       "      <td>0.955332</td>\n",
       "      <td>0.866300</td>\n",
       "      <td>0.954325</td>\n",
       "      <td>0.867933</td>\n",
       "      <td>0.954925</td>\n",
       "      <td>0.861064</td>\n",
       "      <td>0.955642</td>\n",
       "      <td>0.080304</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.449456</td>\n",
       "      <td>1.426413</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.971321</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.868452</td>\n",
       "      <td>0.970758</td>\n",
       "      <td>0.862297</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.970725</td>\n",
       "      <td>0.868356</td>\n",
       "      <td>0.971830</td>\n",
       "      <td>0.860265</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>0.325657</td>\n",
       "      <td>0.166152</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.644428</td>\n",
       "      <td>1.034762</td>\n",
       "      <td>0.863377</td>\n",
       "      <td>0.949759</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864787</td>\n",
       "      <td>0.949658</td>\n",
       "      <td>0.861452</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.865783</td>\n",
       "      <td>0.948862</td>\n",
       "      <td>0.865677</td>\n",
       "      <td>0.949709</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>0.355170</td>\n",
       "      <td>0.066717</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.697450</td>\n",
       "      <td>1.297483</td>\n",
       "      <td>0.854448</td>\n",
       "      <td>0.916289</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.858116</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.917044</td>\n",
       "      <td>0.854692</td>\n",
       "      <td>0.915828</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.916852</td>\n",
       "      <td>0.849361</td>\n",
       "      <td>0.916994</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.749747</td>\n",
       "      <td>1.398028</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>0.941841</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.854827</td>\n",
       "      <td>0.941422</td>\n",
       "      <td>0.853653</td>\n",
       "      <td>0.942444</td>\n",
       "      <td>0.854927</td>\n",
       "      <td>0.940698</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.850019</td>\n",
       "      <td>0.942732</td>\n",
       "      <td>0.223795</td>\n",
       "      <td>0.045179</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.831638</td>\n",
       "      <td>1.871919</td>\n",
       "      <td>0.852954</td>\n",
       "      <td>0.901029</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.853418</td>\n",
       "      <td>0.899656</td>\n",
       "      <td>0.852102</td>\n",
       "      <td>0.901829</td>\n",
       "      <td>0.854504</td>\n",
       "      <td>0.900332</td>\n",
       "      <td>0.856324</td>\n",
       "      <td>0.901028</td>\n",
       "      <td>0.848421</td>\n",
       "      <td>0.902298</td>\n",
       "      <td>1.024601</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.355648</td>\n",
       "      <td>1.691465</td>\n",
       "      <td>0.851742</td>\n",
       "      <td>0.921219</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.854874</td>\n",
       "      <td>0.919581</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.922001</td>\n",
       "      <td>0.851967</td>\n",
       "      <td>0.920985</td>\n",
       "      <td>0.854162</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.847763</td>\n",
       "      <td>0.921787</td>\n",
       "      <td>2.438258</td>\n",
       "      <td>0.436145</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.384682</td>\n",
       "      <td>1.337049</td>\n",
       "      <td>0.851488</td>\n",
       "      <td>0.898193</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.852008</td>\n",
       "      <td>0.897142</td>\n",
       "      <td>0.850740</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>0.853283</td>\n",
       "      <td>0.897431</td>\n",
       "      <td>0.854632</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>0.846776</td>\n",
       "      <td>0.899549</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.074597</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.908687</td>\n",
       "      <td>1.391218</td>\n",
       "      <td>0.850125</td>\n",
       "      <td>0.895643</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.851116</td>\n",
       "      <td>0.894933</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.895931</td>\n",
       "      <td>0.852578</td>\n",
       "      <td>0.894893</td>\n",
       "      <td>0.852705</td>\n",
       "      <td>0.895518</td>\n",
       "      <td>0.844285</td>\n",
       "      <td>0.896941</td>\n",
       "      <td>0.375269</td>\n",
       "      <td>0.127771</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.919834</td>\n",
       "      <td>0.737591</td>\n",
       "      <td>0.847644</td>\n",
       "      <td>0.908087</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.849190</td>\n",
       "      <td>0.907903</td>\n",
       "      <td>0.847686</td>\n",
       "      <td>0.909031</td>\n",
       "      <td>0.849335</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>0.851201</td>\n",
       "      <td>0.907512</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.908958</td>\n",
       "      <td>0.066024</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.517157</td>\n",
       "      <td>1.442622</td>\n",
       "      <td>0.846347</td>\n",
       "      <td>0.888193</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.848062</td>\n",
       "      <td>0.886756</td>\n",
       "      <td>0.845431</td>\n",
       "      <td>0.889129</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>0.887433</td>\n",
       "      <td>0.850167</td>\n",
       "      <td>0.888270</td>\n",
       "      <td>0.841089</td>\n",
       "      <td>0.889376</td>\n",
       "      <td>1.479430</td>\n",
       "      <td>0.096807</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.609228</td>\n",
       "      <td>1.193469</td>\n",
       "      <td>0.845849</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.847310</td>\n",
       "      <td>0.886215</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.887860</td>\n",
       "      <td>0.848489</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.847911</td>\n",
       "      <td>0.886579</td>\n",
       "      <td>0.839679</td>\n",
       "      <td>0.888048</td>\n",
       "      <td>0.741049</td>\n",
       "      <td>0.241642</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.111405</td>\n",
       "      <td>1.080909</td>\n",
       "      <td>0.845811</td>\n",
       "      <td>0.884859</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 3), 'nai...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.846559</td>\n",
       "      <td>0.883830</td>\n",
       "      <td>0.845290</td>\n",
       "      <td>0.885734</td>\n",
       "      <td>0.846891</td>\n",
       "      <td>0.883815</td>\n",
       "      <td>0.849603</td>\n",
       "      <td>0.884581</td>\n",
       "      <td>0.840713</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>0.334877</td>\n",
       "      <td>0.119513</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.198734</td>\n",
       "      <td>1.070929</td>\n",
       "      <td>0.844486</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.845760</td>\n",
       "      <td>0.880259</td>\n",
       "      <td>0.844304</td>\n",
       "      <td>0.882374</td>\n",
       "      <td>0.845246</td>\n",
       "      <td>0.880173</td>\n",
       "      <td>0.848005</td>\n",
       "      <td>0.880446</td>\n",
       "      <td>0.839114</td>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.080218</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.638363</td>\n",
       "      <td>1.588426</td>\n",
       "      <td>0.841375</td>\n",
       "      <td>0.912123</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 2), 'nai...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.841626</td>\n",
       "      <td>0.911663</td>\n",
       "      <td>0.842283</td>\n",
       "      <td>0.912708</td>\n",
       "      <td>0.843367</td>\n",
       "      <td>0.911516</td>\n",
       "      <td>0.842506</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.837093</td>\n",
       "      <td>0.912635</td>\n",
       "      <td>1.083157</td>\n",
       "      <td>0.619391</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.700297</td>\n",
       "      <td>1.175961</td>\n",
       "      <td>0.839824</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.841626</td>\n",
       "      <td>0.888119</td>\n",
       "      <td>0.839511</td>\n",
       "      <td>0.890069</td>\n",
       "      <td>0.841675</td>\n",
       "      <td>0.889619</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.889551</td>\n",
       "      <td>0.833286</td>\n",
       "      <td>0.890574</td>\n",
       "      <td>0.800656</td>\n",
       "      <td>0.262959</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.304115</td>\n",
       "      <td>1.267096</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.919015</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.839981</td>\n",
       "      <td>0.918536</td>\n",
       "      <td>0.837632</td>\n",
       "      <td>0.919664</td>\n",
       "      <td>0.841769</td>\n",
       "      <td>0.919317</td>\n",
       "      <td>0.840344</td>\n",
       "      <td>0.918379</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.919179</td>\n",
       "      <td>0.601585</td>\n",
       "      <td>0.276193</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.836203</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.837531</td>\n",
       "      <td>0.891097</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.839183</td>\n",
       "      <td>0.889752</td>\n",
       "      <td>0.837773</td>\n",
       "      <td>0.891643</td>\n",
       "      <td>0.838197</td>\n",
       "      <td>0.891169</td>\n",
       "      <td>0.840626</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.831876</td>\n",
       "      <td>0.891948</td>\n",
       "      <td>0.213537</td>\n",
       "      <td>0.054272</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.274081</td>\n",
       "      <td>0.888501</td>\n",
       "      <td>0.836009</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.836552</td>\n",
       "      <td>0.882209</td>\n",
       "      <td>0.835330</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.837915</td>\n",
       "      <td>0.881595</td>\n",
       "      <td>0.837900</td>\n",
       "      <td>0.881363</td>\n",
       "      <td>0.832346</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.136346</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.037888</td>\n",
       "      <td>0.828935</td>\n",
       "      <td>0.834214</td>\n",
       "      <td>0.865907</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.834813</td>\n",
       "      <td>0.865009</td>\n",
       "      <td>0.832323</td>\n",
       "      <td>0.866689</td>\n",
       "      <td>0.836599</td>\n",
       "      <td>0.865101</td>\n",
       "      <td>0.835597</td>\n",
       "      <td>0.865633</td>\n",
       "      <td>0.831735</td>\n",
       "      <td>0.867103</td>\n",
       "      <td>0.269981</td>\n",
       "      <td>0.135024</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.132897</td>\n",
       "      <td>1.057742</td>\n",
       "      <td>0.833894</td>\n",
       "      <td>0.878301</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.834813</td>\n",
       "      <td>0.878614</td>\n",
       "      <td>0.833780</td>\n",
       "      <td>0.879589</td>\n",
       "      <td>0.835284</td>\n",
       "      <td>0.876919</td>\n",
       "      <td>0.835503</td>\n",
       "      <td>0.877733</td>\n",
       "      <td>0.830090</td>\n",
       "      <td>0.878650</td>\n",
       "      <td>0.745776</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.901741</td>\n",
       "      <td>0.860692</td>\n",
       "      <td>0.832663</td>\n",
       "      <td>0.863952</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.834390</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.831243</td>\n",
       "      <td>0.864986</td>\n",
       "      <td>0.834579</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.836490</td>\n",
       "      <td>0.863424</td>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.865388</td>\n",
       "      <td>0.470721</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.069191</td>\n",
       "      <td>0.952054</td>\n",
       "      <td>0.831845</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.832605</td>\n",
       "      <td>0.861638</td>\n",
       "      <td>0.830350</td>\n",
       "      <td>0.863423</td>\n",
       "      <td>0.834109</td>\n",
       "      <td>0.861342</td>\n",
       "      <td>0.832871</td>\n",
       "      <td>0.861803</td>\n",
       "      <td>0.829291</td>\n",
       "      <td>0.863579</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.042215</td>\n",
       "      <td>0.745573</td>\n",
       "      <td>0.830501</td>\n",
       "      <td>0.858927</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.831384</td>\n",
       "      <td>0.857960</td>\n",
       "      <td>0.828753</td>\n",
       "      <td>0.859394</td>\n",
       "      <td>0.832417</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.833952</td>\n",
       "      <td>0.858115</td>\n",
       "      <td>0.826001</td>\n",
       "      <td>0.860736</td>\n",
       "      <td>0.332888</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.825008</td>\n",
       "      <td>0.771074</td>\n",
       "      <td>0.827842</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'count_vectorizer__ngram_range': (1, 1), 'nai...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.828988</td>\n",
       "      <td>0.854330</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>0.855317</td>\n",
       "      <td>0.829832</td>\n",
       "      <td>0.853577</td>\n",
       "      <td>0.830051</td>\n",
       "      <td>0.853756</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.855743</td>\n",
       "      <td>0.120193</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "15       6.340238         1.058096         0.865144          0.955064   \n",
       "6        8.449456         1.426413         0.864956          0.971321   \n",
       "1        6.644428         1.034762         0.863377          0.949759   \n",
       "0        7.697450         1.297483         0.854448          0.916289   \n",
       "12       8.749747         1.398028         0.853706          0.941841   \n",
       "22      11.831638         1.871919         0.852954          0.901029   \n",
       "24      10.355648         1.691465         0.851742          0.921219   \n",
       "5        8.384682         1.337049         0.851488          0.898193   \n",
       "14       8.908687         1.391218         0.850125          0.895643   \n",
       "10       3.919834         0.737591         0.847644          0.908087   \n",
       "2        9.517157         1.442622         0.846347          0.888193   \n",
       "3        8.609228         1.193469         0.845849          0.886917   \n",
       "8        8.111405         1.080909         0.845811          0.884859   \n",
       "11       6.198734         1.070929         0.844486          0.881144   \n",
       "21      10.638363         1.588426         0.841375          0.912123   \n",
       "20       5.700297         1.175961         0.839824          0.889586   \n",
       "23       6.304115         1.267096         0.838612          0.919015   \n",
       "9        3.836203         0.760584         0.837531          0.891097   \n",
       "17       5.274081         0.888501         0.836009          0.882368   \n",
       "7        4.037888         0.828935         0.834214          0.865907   \n",
       "19       5.132897         1.057742         0.833894          0.878301   \n",
       "16       3.901741         0.860692         0.832663          0.863952   \n",
       "18       5.069191         0.952054         0.831845          0.862357   \n",
       "4        4.042215         0.745573         0.830501          0.858927   \n",
       "13       3.825008         0.771074         0.827842          0.854545   \n",
       "\n",
       "   param_count_vectorizer__min_df param_count_vectorizer__ngram_range  \\\n",
       "15                              1                              (1, 2)   \n",
       "6                               1                              (1, 3)   \n",
       "1                               1                              (1, 2)   \n",
       "0                               2                              (1, 3)   \n",
       "12                              1                              (1, 3)   \n",
       "22                              2                              (1, 3)   \n",
       "24                              2                              (1, 2)   \n",
       "5                               2                              (1, 3)   \n",
       "14                              2                              (1, 3)   \n",
       "10                              1                              (1, 1)   \n",
       "2                               3                              (1, 3)   \n",
       "3                               2                              (1, 2)   \n",
       "8                               3                              (1, 3)   \n",
       "11                              3                              (1, 2)   \n",
       "21                              1                              (1, 2)   \n",
       "20                              2                              (1, 1)   \n",
       "23                              1                              (1, 1)   \n",
       "9                               2                              (1, 1)   \n",
       "17                              1                              (1, 1)   \n",
       "7                               2                              (1, 1)   \n",
       "19                              1                              (1, 1)   \n",
       "16                              3                              (1, 1)   \n",
       "18                              2                              (1, 1)   \n",
       "4                               3                              (1, 1)   \n",
       "13                              3                              (1, 1)   \n",
       "\n",
       "   param_naive_bayes__alpha  \\\n",
       "15                      0.1   \n",
       "6                      0.01   \n",
       "1                       0.2   \n",
       "0                      0.01   \n",
       "12                      0.5   \n",
       "22                      0.3   \n",
       "24                        0   \n",
       "5                       0.4   \n",
       "14                      0.5   \n",
       "10                      0.1   \n",
       "2                       0.1   \n",
       "3                       0.8   \n",
       "8                       0.2   \n",
       "11                      0.3   \n",
       "21                      0.9   \n",
       "20                     0.01   \n",
       "23                        0   \n",
       "9                     0.001   \n",
       "17                      0.7   \n",
       "7                       0.8   \n",
       "19                      0.8   \n",
       "16                      0.4   \n",
       "18                        1   \n",
       "4                       0.7   \n",
       "13                        1   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "15  {'count_vectorizer__ngram_range': (1, 2), 'nai...                1   \n",
       "6   {'count_vectorizer__ngram_range': (1, 3), 'nai...                2   \n",
       "1   {'count_vectorizer__ngram_range': (1, 2), 'nai...                3   \n",
       "0   {'count_vectorizer__ngram_range': (1, 3), 'nai...                4   \n",
       "12  {'count_vectorizer__ngram_range': (1, 3), 'nai...                5   \n",
       "22  {'count_vectorizer__ngram_range': (1, 3), 'nai...                6   \n",
       "24  {'count_vectorizer__ngram_range': (1, 2), 'nai...                7   \n",
       "5   {'count_vectorizer__ngram_range': (1, 3), 'nai...                8   \n",
       "14  {'count_vectorizer__ngram_range': (1, 3), 'nai...                9   \n",
       "10  {'count_vectorizer__ngram_range': (1, 1), 'nai...               10   \n",
       "2   {'count_vectorizer__ngram_range': (1, 3), 'nai...               11   \n",
       "3   {'count_vectorizer__ngram_range': (1, 2), 'nai...               12   \n",
       "8   {'count_vectorizer__ngram_range': (1, 3), 'nai...               13   \n",
       "11  {'count_vectorizer__ngram_range': (1, 2), 'nai...               14   \n",
       "21  {'count_vectorizer__ngram_range': (1, 2), 'nai...               15   \n",
       "20  {'count_vectorizer__ngram_range': (1, 1), 'nai...               16   \n",
       "23  {'count_vectorizer__ngram_range': (1, 1), 'nai...               17   \n",
       "9   {'count_vectorizer__ngram_range': (1, 1), 'nai...               18   \n",
       "17  {'count_vectorizer__ngram_range': (1, 1), 'nai...               19   \n",
       "7   {'count_vectorizer__ngram_range': (1, 1), 'nai...               20   \n",
       "19  {'count_vectorizer__ngram_range': (1, 1), 'nai...               21   \n",
       "16  {'count_vectorizer__ngram_range': (1, 1), 'nai...               22   \n",
       "18  {'count_vectorizer__ngram_range': (1, 1), 'nai...               23   \n",
       "4   {'count_vectorizer__ngram_range': (1, 1), 'nai...               24   \n",
       "13  {'count_vectorizer__ngram_range': (1, 1), 'nai...               25   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "15           0.866479            0.955097           0.863942   \n",
       "6            0.868452            0.970758           0.862297   \n",
       "1            0.864787            0.949658           0.861452   \n",
       "0            0.858116            0.914729           0.852525   \n",
       "12           0.854827            0.941422           0.853653   \n",
       "22           0.853418            0.899656           0.852102   \n",
       "24           0.854874            0.919581           0.849941   \n",
       "5            0.852008            0.897142           0.850740   \n",
       "14           0.851116            0.894933           0.849941   \n",
       "10           0.849190            0.907903           0.847686   \n",
       "2            0.848062            0.886756           0.845431   \n",
       "3            0.847310            0.886215           0.845854   \n",
       "8            0.846559            0.883830           0.845290   \n",
       "11           0.845760            0.880259           0.844304   \n",
       "21           0.841626            0.911663           0.842283   \n",
       "20           0.841626            0.888119           0.839511   \n",
       "23           0.839981            0.918536           0.837632   \n",
       "9            0.839183            0.889752           0.837773   \n",
       "17           0.836552            0.882209           0.835330   \n",
       "7            0.834813            0.865009           0.832323   \n",
       "19           0.834813            0.878614           0.833780   \n",
       "16           0.834390            0.863118           0.831243   \n",
       "18           0.832605            0.861638           0.830350   \n",
       "4            0.831384            0.857960           0.828753   \n",
       "13           0.828988            0.854330           0.826591   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "15            0.955332           0.866300            0.954325   \n",
       "6             0.971733           0.865407            0.970725   \n",
       "1             0.949775           0.865783            0.948862   \n",
       "0             0.917044           0.854692            0.915828   \n",
       "12            0.942444           0.854927            0.940698   \n",
       "22            0.901829           0.854504            0.900332   \n",
       "24            0.922001           0.851967            0.920985   \n",
       "5             0.898681           0.853283            0.897431   \n",
       "14            0.895931           0.852578            0.894893   \n",
       "10            0.909031           0.849335            0.907029   \n",
       "2             0.889129           0.846985            0.887433   \n",
       "3             0.887860           0.848489            0.885883   \n",
       "8             0.885734           0.846891            0.883815   \n",
       "11            0.882374           0.845246            0.880173   \n",
       "21            0.912708           0.843367            0.911516   \n",
       "20            0.890069           0.841675            0.889619   \n",
       "23            0.919664           0.841769            0.919317   \n",
       "9             0.891643           0.838197            0.891169   \n",
       "17            0.883572           0.837915            0.881595   \n",
       "7             0.866689           0.836599            0.865101   \n",
       "19            0.879589           0.835284            0.876919   \n",
       "16            0.864986           0.834579            0.862846   \n",
       "18            0.863423           0.834109            0.861342   \n",
       "4             0.859394           0.832417            0.858428   \n",
       "13            0.855317           0.829832            0.853577   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "15           0.867933            0.954925           0.861064   \n",
       "6            0.868356            0.971830           0.860265   \n",
       "1            0.865677            0.949709           0.859184   \n",
       "0            0.857546            0.916852           0.849361   \n",
       "12           0.855102            0.941909           0.850019   \n",
       "22           0.856324            0.901028           0.848421   \n",
       "24           0.854162            0.921739           0.847763   \n",
       "5            0.854632            0.898162           0.846776   \n",
       "14           0.852705            0.895518           0.844285   \n",
       "10           0.851201            0.907512           0.840807   \n",
       "2            0.850167            0.888270           0.841089   \n",
       "3            0.847911            0.886579           0.839679   \n",
       "8            0.849603            0.884581           0.840713   \n",
       "11           0.848005            0.880446           0.839114   \n",
       "21           0.842506            0.912094           0.837093   \n",
       "20           0.843023            0.889551           0.833286   \n",
       "23           0.840344            0.918379           0.833333   \n",
       "9            0.840626            0.890972           0.831876   \n",
       "17           0.837900            0.881363           0.832346   \n",
       "7            0.835597            0.865633           0.831735   \n",
       "19           0.835503            0.877733           0.830090   \n",
       "16           0.836490            0.863424           0.826612   \n",
       "18           0.832871            0.861803           0.829291   \n",
       "4            0.833952            0.858115           0.826001   \n",
       "13           0.830051            0.853756           0.823745   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "15            0.955642      0.080304        0.025373        0.002408   \n",
       "6             0.971560      0.325657        0.166152        0.003257   \n",
       "1             0.950791      0.355170        0.066717        0.002621   \n",
       "0             0.916994      0.593889        0.083777        0.003246   \n",
       "12            0.942732      0.223795        0.045179        0.001913   \n",
       "22            0.902298      1.024601        0.276042        0.002655   \n",
       "24            0.921787      2.438258        0.436145        0.002638   \n",
       "5             0.899549      0.095274        0.074597        0.002688   \n",
       "14            0.896941      0.375269        0.127771        0.003092   \n",
       "10            0.908958      0.066024        0.027876        0.003596   \n",
       "2             0.889376      1.479430        0.096807        0.003047   \n",
       "3             0.888048      0.741049        0.241642        0.003207   \n",
       "8             0.886333      0.334877        0.119513        0.002911   \n",
       "11            0.882468      0.080218        0.037614        0.002948   \n",
       "21            0.912635      1.083157        0.619391        0.002212   \n",
       "20            0.890574      0.800656        0.262959        0.003456   \n",
       "23            0.919179      0.601585        0.276193        0.002955   \n",
       "9             0.891948      0.213537        0.054272        0.002993   \n",
       "17            0.883103      0.902276        0.136346        0.002068   \n",
       "7             0.867103      0.269981        0.135024        0.001880   \n",
       "19            0.878650      0.745776        0.159877        0.001992   \n",
       "16            0.865388      0.470721        0.198061        0.003462   \n",
       "18            0.863579      0.294493        0.117046        0.001761   \n",
       "4             0.860736      0.332888        0.026100        0.002816   \n",
       "13            0.855743      0.120193        0.039147        0.002387   \n",
       "\n",
       "    std_train_score  \n",
       "15         0.000441  \n",
       "6          0.000481  \n",
       "1          0.000613  \n",
       "0          0.000898  \n",
       "12         0.000727  \n",
       "22         0.000961  \n",
       "24         0.000888  \n",
       "5          0.000868  \n",
       "14         0.000755  \n",
       "10         0.000792  \n",
       "2          0.000992  \n",
       "3          0.000877  \n",
       "8          0.001016  \n",
       "11         0.001047  \n",
       "21         0.000487  \n",
       "20         0.000820  \n",
       "23         0.000484  \n",
       "9          0.000755  \n",
       "17         0.000851  \n",
       "7          0.000845  \n",
       "19         0.000907  \n",
       "16         0.001032  \n",
       "18         0.000947  \n",
       "4          0.001033  \n",
       "13         0.000853  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(random_grid_search.cv_results_)\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using names is not a better idea than using nutrients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for products without food groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518912, 26)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With valid nutrients\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['salt_100g'] <= 100]\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['sugars_100g'] <= 100]\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['carbohydrates_100g'] <= 100]\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['fat_100g'] <= 100]\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['proteins_100g'] <= 100]\n",
    "openfoodfacts_foodgroup_nutrients = openfoodfacts_foodgroup_nutrients[openfoodfacts_foodgroup_nutrients['saturated-fat_100g'] <= 100]\n",
    "\n",
    "openfoodfacts_foodgroup_nutrients.shape #518912 x 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=40, max_features=2, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=50, verbose=0, warm_start=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=-1,\n",
      "            oob_score=False, random_state=50, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Selected models\n",
    "print(clf_nutrients_rf)\n",
    "print(clf_nutrients_rf_light)\n",
    "\n",
    "# Save the model to disk\n",
    "filename = '../../data/clf_nutrients_rf_' + level_groupe +'.sav'\n",
    "pickle.dump(clf_nutrients_rf, open(filename, 'wb'))\n",
    "\n",
    "# Save the light model to disk\n",
    "filename_light = '../../data/clf_nutrients_rf_' + level_groupe +'_light.sav'\n",
    "pickle.dump(clf_nutrients_rf_light, open(filename_light, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "openfoodfacts_foodgroup_nutrients[level_groupe + '_hat'] = clf_nutrients_rf.predict(openfoodfacts_foodgroup_nutrients[['salt_100g', 'sugars_100g',\n",
    "                                                                                    'carbohydrates_100g', 'fat_100g',\n",
    "                                                                                    'proteins_100g', 'saturated-fat_100g']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not replace foodgroup when it was available !\n",
    "openfoodfacts_foodgroup_nutrients['foodgroup'] = np.where(pd.isnull(openfoodfacts_foodgroup_nutrients[level_groupe]), \n",
    "                                                          openfoodfacts_foodgroup_nutrients[level_groupe + '_hat'], \n",
    "                                                          openfoodfacts_foodgroup_nutrients[level_groupe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAN</th>\n",
       "      <th>product_name</th>\n",
       "      <th>pnns_groups_1</th>\n",
       "      <th>pnns_groups_2</th>\n",
       "      <th>groupeAlim_2</th>\n",
       "      <th>groupeAlim_2_hat</th>\n",
       "      <th>foodgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138107</th>\n",
       "      <td>0290779044675</td>\n",
       "      <td>Palette de porc a l'emmental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120717</th>\n",
       "      <td>0098437240335</td>\n",
       "      <td>Casey's General Store, Assorted Fruit Sours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409970</th>\n",
       "      <td>3559040007052</td>\n",
       "      <td>Brioche aux fruits confits La Coupiagaise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145157</th>\n",
       "      <td>0621498710419</td>\n",
       "      <td>Protidiet Potage Arome Poulet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274717</th>\n",
       "      <td>3116740026136</td>\n",
       "      <td>Bestfizz</td>\n",
       "      <td>Sugary snacks</td>\n",
       "      <td>Sweets</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88666</th>\n",
       "      <td>0072250045490</td>\n",
       "      <td>Cobblestone Bread Co, Bagels, Original</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395740</th>\n",
       "      <td>3474340020092</td>\n",
       "      <td>Chocolat en poudre goût épices</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602802</th>\n",
       "      <td>7622300725051</td>\n",
       "      <td>Cadbury Dairy Milk With Crunchie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644180</th>\n",
       "      <td>8436014444516</td>\n",
       "      <td>Golosinas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130904</th>\n",
       "      <td>0211405023819</td>\n",
       "      <td>Jambon cuit superieur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23594</th>\n",
       "      <td>0024182210309</td>\n",
       "      <td>Udon Wheat Pasta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664399</th>\n",
       "      <td>8722700054795</td>\n",
       "      <td>Moutarde au vin blanc à la tomate séchée et pi...</td>\n",
       "      <td>Fat and sauces</td>\n",
       "      <td>Dressings and sauces</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424452</th>\n",
       "      <td>3580280530055</td>\n",
       "      <td>Infusion Detox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230268</th>\n",
       "      <td>22115386</td>\n",
       "      <td>Erdnüsse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>3263856412916</td>\n",
       "      <td>Yaourts au lait entier Nature</td>\n",
       "      <td>Milk and dairy products</td>\n",
       "      <td>Milk and yogurt</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248022</th>\n",
       "      <td>2609844065794</td>\n",
       "      <td>Baies de toi sechees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24185</th>\n",
       "      <td>0025293002999</td>\n",
       "      <td>Dairy-Free Yogurt Alternative, Tropical Pineapple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377050</th>\n",
       "      <td>3390953001115</td>\n",
       "      <td>Carré de Lorraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fromage</td>\n",
       "      <td>Fromage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104981</th>\n",
       "      <td>0077958690232</td>\n",
       "      <td>Shrimp &amp; Roasted Corn Chowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587837</th>\n",
       "      <td>7610849266951</td>\n",
       "      <td>Naturaplan Bio Kürbissuppe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16879</th>\n",
       "      <td>0019061091445</td>\n",
       "      <td>Pastel Pretzels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75794</th>\n",
       "      <td>0066701007120</td>\n",
       "      <td>Sauce à Poutine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>3165950217261</td>\n",
       "      <td>Salade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259739</th>\n",
       "      <td>3024720020343</td>\n",
       "      <td>Rillettes sans graisses ajoutées</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>0011110878304</td>\n",
       "      <td>Waffles, Blueberry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185457</th>\n",
       "      <td>0835107139045</td>\n",
       "      <td>Wings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434260</th>\n",
       "      <td>3596710747542</td>\n",
       "      <td>Riz cantonais</td>\n",
       "      <td>Composite foods</td>\n",
       "      <td>One-dish meals</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366968</th>\n",
       "      <td>3350033317123</td>\n",
       "      <td>Beurre allégé doux 60% MG</td>\n",
       "      <td>Fat and sauces</td>\n",
       "      <td>Fats</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648640</th>\n",
       "      <td>8480000822703</td>\n",
       "      <td>Pico reventao con aceite de oliva virgen extra 4%</td>\n",
       "      <td>Cereals and potatoes</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12078</th>\n",
       "      <td>0013562001354</td>\n",
       "      <td>Macaroni &amp; Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360189</th>\n",
       "      <td>3333040000523</td>\n",
       "      <td>Petit beurre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115212</th>\n",
       "      <td>0086341607160</td>\n",
       "      <td>Fra Diavolo Arribiata - Hot And Spicy Pasta Sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>0010532174155</td>\n",
       "      <td>Mcsteven's, Chocolate Cocoa!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419879</th>\n",
       "      <td>3564700742099</td>\n",
       "      <td>Crème onctueuse au café</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44150</th>\n",
       "      <td>0041220909278</td>\n",
       "      <td>Borracho Beans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85898</th>\n",
       "      <td>0071725713315</td>\n",
       "      <td>Energy Mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296034</th>\n",
       "      <td>3240930007787</td>\n",
       "      <td>Demi-lune, Tomate Basilic Mozzarella</td>\n",
       "      <td>Cereals and potatoes</td>\n",
       "      <td>Cereals</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581901</th>\n",
       "      <td>7501464312096</td>\n",
       "      <td>El diablo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615910</th>\n",
       "      <td>8005360001522</td>\n",
       "      <td>Green Pesto</td>\n",
       "      <td>Fat and sauces</td>\n",
       "      <td>Dressings and sauces</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478633</th>\n",
       "      <td>3760258880195</td>\n",
       "      <td>ORANGETTES NOIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374057</th>\n",
       "      <td>3379145032878</td>\n",
       "      <td>Nouilles Style Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477674</th>\n",
       "      <td>3760246650014</td>\n",
       "      <td>Jus de pomme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644472</th>\n",
       "      <td>8436033936023</td>\n",
       "      <td>Taquiyod de pavo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249857</th>\n",
       "      <td>2683595024934</td>\n",
       "      <td>Emmental Français</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fromage</td>\n",
       "      <td>Fromage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237684</th>\n",
       "      <td>24063463</td>\n",
       "      <td>Preparado a base de extracto de coco y agua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "      <td>Produits laitiers (hors fromage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391589</th>\n",
       "      <td>3450970140805</td>\n",
       "      <td>Saumon Rose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66008</th>\n",
       "      <td>0049800137974</td>\n",
       "      <td>Celebration Cake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560741</th>\n",
       "      <td>5601066300803</td>\n",
       "      <td>Fios de aletria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237602</th>\n",
       "      <td>24050944</td>\n",
       "      <td>Pois chiches aux legumes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492829</th>\n",
       "      <td>4007791842365</td>\n",
       "      <td>Spargelschinken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332389</th>\n",
       "      <td>3266191017136</td>\n",
       "      <td>Pur Arabica soluble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372094</th>\n",
       "      <td>3370077586392</td>\n",
       "      <td>Chocolat noir fourré Coeur Caramel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263381</th>\n",
       "      <td>3038680063166</td>\n",
       "      <td>Filets de harengs fumés</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>Poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286483</th>\n",
       "      <td>3188720002225</td>\n",
       "      <td>Les recettes d'Eugène</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>Poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455150</th>\n",
       "      <td>3760023454101</td>\n",
       "      <td>Gingembre morceaux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50579</th>\n",
       "      <td>0041376954023</td>\n",
       "      <td>Crispy Chocolate Hearts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460214</th>\n",
       "      <td>3760066060321</td>\n",
       "      <td>Tiramisu fraise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311434</th>\n",
       "      <td>3256220267762</td>\n",
       "      <td>Tuiles saveur citrons</td>\n",
       "      <td>Sugary snacks</td>\n",
       "      <td>Biscuits and cakes</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277256</th>\n",
       "      <td>3155700003961</td>\n",
       "      <td>Huile vierge trio biologique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381331</th>\n",
       "      <td>3412290074499</td>\n",
       "      <td>Madame Loïk a la betterave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fromage</td>\n",
       "      <td>Fromage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220178</th>\n",
       "      <td>20353742</td>\n",
       "      <td>Sopa de legumes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153344</th>\n",
       "      <td>0688267150524</td>\n",
       "      <td>Nature's Promise, Organic Fruit Punch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303340</th>\n",
       "      <td>3250391373604</td>\n",
       "      <td>2 demi baguettes précuite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238428</th>\n",
       "      <td>2424271049922</td>\n",
       "      <td>Osso bucco de veai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205919</th>\n",
       "      <td>0939222500619</td>\n",
       "      <td>Tuna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>Poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385275</th>\n",
       "      <td>3428274140029</td>\n",
       "      <td>Milk'nGO</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Sweetened beverages</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612761</th>\n",
       "      <td>8002816806410</td>\n",
       "      <td>Céréales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents non raffinés</td>\n",
       "      <td>Féculents non raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44982</th>\n",
       "      <td>0041250642893</td>\n",
       "      <td>Organic Sloppy Joe Sauce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230014</th>\n",
       "      <td>2209686008098</td>\n",
       "      <td>Poulet fermier blanc</td>\n",
       "      <td>Fish Meat Eggs</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584508</th>\n",
       "      <td>7610200319234</td>\n",
       "      <td>Bio Haselnüsse Gemahlen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196313</th>\n",
       "      <td>0857750003511</td>\n",
       "      <td>Uncured Jalapeno Salami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "      <td>Viande, oeufs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115320</th>\n",
       "      <td>0086600102801</td>\n",
       "      <td>Solid White Albacore Premium Tuna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>Poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147182</th>\n",
       "      <td>0638102646620</td>\n",
       "      <td>Marcona Almond &amp; Apricot Bar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443582</th>\n",
       "      <td>3700152400082</td>\n",
       "      <td>Chocolat Bonnat chocolat au lait &amp;quot;sans su...</td>\n",
       "      <td>Sugary snacks</td>\n",
       "      <td>Chocolate products</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271795</th>\n",
       "      <td>3101740010056</td>\n",
       "      <td>Confiture de framboise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150830</th>\n",
       "      <td>0674971524041</td>\n",
       "      <td>Dancing Deer Baking Co, Dessert Bites, Caramel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22115</th>\n",
       "      <td>0023000438642</td>\n",
       "      <td>Popcorn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415112</th>\n",
       "      <td>3560071017521</td>\n",
       "      <td>Houmous aux olives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>Poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50598</th>\n",
       "      <td>0041380000815</td>\n",
       "      <td>Yellow Popcorn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "      <td>Féculents raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236734</th>\n",
       "      <td>23561861</td>\n",
       "      <td>Brauner Rohr-Rohzucker</td>\n",
       "      <td>Sugary snacks</td>\n",
       "      <td>Sweets</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448726</th>\n",
       "      <td>3700593403765</td>\n",
       "      <td>Velouté légumes du soleil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334419</th>\n",
       "      <td>3267853184418</td>\n",
       "      <td>Biscuits apéritifs sticks et bretzels salé</td>\n",
       "      <td>Salty snacks</td>\n",
       "      <td>Appetizers</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315976</th>\n",
       "      <td>3256226761233</td>\n",
       "      <td>Mayonnaise à la moutarde de Dijon</td>\n",
       "      <td>Fat and sauces</td>\n",
       "      <td>Dressings and sauces</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195703</th>\n",
       "      <td>0857037005009</td>\n",
       "      <td>Scramble, Ranchers Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321934</th>\n",
       "      <td>3258831446000</td>\n",
       "      <td>Moutarde de Dijon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161474</th>\n",
       "      <td>0719283985323</td>\n",
       "      <td>Beef Ravioli In Tomato &amp; Meat Sauce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183739</th>\n",
       "      <td>0820581008765</td>\n",
       "      <td>Sharp Cracker Cut Cheddar Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fromage</td>\n",
       "      <td>Fromage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278826</th>\n",
       "      <td>3165950216349</td>\n",
       "      <td>Les saladieres</td>\n",
       "      <td>Composite foods</td>\n",
       "      <td>One-dish meals</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95693</th>\n",
       "      <td>0074410278236</td>\n",
       "      <td>Soybean Paste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140472</th>\n",
       "      <td>04131832086</td>\n",
       "      <td>Cheesecake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596428</th>\n",
       "      <td>7613331466945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533322</th>\n",
       "      <td>5053827144018</td>\n",
       "      <td>Crunchy Muesli With Chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Féculents non raffinés</td>\n",
       "      <td>Féculents non raffinés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>0039400016380</td>\n",
       "      <td>Bean Pot, Vegetarian Baked Beans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529266</th>\n",
       "      <td>5021812004616</td>\n",
       "      <td>Fruity raspberry lemonade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166458</th>\n",
       "      <td>0737094211103</td>\n",
       "      <td>Roasted Almonds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229284</th>\n",
       "      <td>22043542</td>\n",
       "      <td>Cogumelos laminados</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Légumes</td>\n",
       "      <td>Légumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165960</th>\n",
       "      <td>0735199552008</td>\n",
       "      <td>Beef Franks In A Blanket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plats préparés</td>\n",
       "      <td>Plats préparés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507414</th>\n",
       "      <td>42183112</td>\n",
       "      <td>Dextrose Täfelchen Minis Limette</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>0020685001154</td>\n",
       "      <td>Kettle Cooked Potato Chips, Sweet Red Chili</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "      <td>Produits gras sucrés salés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307899</th>\n",
       "      <td>3250547813190</td>\n",
       "      <td>Moutarde de Dijon</td>\n",
       "      <td>Fat and sauces</td>\n",
       "      <td>Dressings and sauces</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "      <td>Matières grasses ajoutées</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EAN                                       product_name  \\\n",
       "138107  0290779044675                       Palette de porc a l'emmental   \n",
       "120717  0098437240335        Casey's General Store, Assorted Fruit Sours   \n",
       "409970  3559040007052          Brioche aux fruits confits La Coupiagaise   \n",
       "145157  0621498710419                      Protidiet Potage Arome Poulet   \n",
       "274717  3116740026136                                           Bestfizz   \n",
       "88666   0072250045490             Cobblestone Bread Co, Bagels, Original   \n",
       "395740  3474340020092                     Chocolat en poudre goût épices   \n",
       "602802  7622300725051                   Cadbury Dairy Milk With Crunchie   \n",
       "644180  8436014444516                                          Golosinas   \n",
       "130904  0211405023819                              Jambon cuit superieur   \n",
       "23594   0024182210309                                   Udon Wheat Pasta   \n",
       "664399  8722700054795  Moutarde au vin blanc à la tomate séchée et pi...   \n",
       "424452  3580280530055                                     Infusion Detox   \n",
       "230268       22115386                                           Erdnüsse   \n",
       "327711  3263856412916                      Yaourts au lait entier Nature   \n",
       "248022  2609844065794                               Baies de toi sechees   \n",
       "24185   0025293002999  Dairy-Free Yogurt Alternative, Tropical Pineapple   \n",
       "377050  3390953001115                                  Carré de Lorraine   \n",
       "104981  0077958690232                      Shrimp & Roasted Corn Chowder   \n",
       "587837  7610849266951                         Naturaplan Bio Kürbissuppe   \n",
       "16879   0019061091445                                    Pastel Pretzels   \n",
       "75794   0066701007120                                    Sauce à Poutine   \n",
       "278857  3165950217261                                             Salade   \n",
       "259739  3024720020343                   Rillettes sans graisses ajoutées   \n",
       "5361    0011110878304                                 Waffles, Blueberry   \n",
       "185457  0835107139045                                              Wings   \n",
       "434260  3596710747542                                      Riz cantonais   \n",
       "366968  3350033317123                          Beurre allégé doux 60% MG   \n",
       "648640  8480000822703  Pico reventao con aceite de oliva virgen extra 4%   \n",
       "12078   0013562001354                                  Macaroni & Cheese   \n",
       "360189  3333040000523                                       Petit beurre   \n",
       "115212  0086341607160  Fra Diavolo Arribiata - Hot And Spicy Pasta Sa...   \n",
       "2408    0010532174155                       Mcsteven's, Chocolate Cocoa!   \n",
       "419879  3564700742099                            Crème onctueuse au café   \n",
       "44150   0041220909278                                     Borracho Beans   \n",
       "85898   0071725713315                                         Energy Mix   \n",
       "296034  3240930007787               Demi-lune, Tomate Basilic Mozzarella   \n",
       "581901  7501464312096                                          El diablo   \n",
       "615910  8005360001522                                        Green Pesto   \n",
       "478633  3760258880195                                    ORANGETTES NOIR   \n",
       "374057  3379145032878                             Nouilles Style Beijing   \n",
       "477674  3760246650014                                       Jus de pomme   \n",
       "644472  8436033936023                                   Taquiyod de pavo   \n",
       "249857  2683595024934                                  Emmental Français   \n",
       "237684       24063463        Preparado a base de extracto de coco y agua   \n",
       "391589  3450970140805                                        Saumon Rose   \n",
       "66008   0049800137974                                   Celebration Cake   \n",
       "560741  5601066300803                                    Fios de aletria   \n",
       "237602       24050944                           Pois chiches aux legumes   \n",
       "492829  4007791842365                                    Spargelschinken   \n",
       "332389  3266191017136                                Pur Arabica soluble   \n",
       "372094  3370077586392                 Chocolat noir fourré Coeur Caramel   \n",
       "263381  3038680063166                            Filets de harengs fumés   \n",
       "286483  3188720002225                              Les recettes d'Eugène   \n",
       "455150  3760023454101                                 Gingembre morceaux   \n",
       "50579   0041376954023                            Crispy Chocolate Hearts   \n",
       "460214  3760066060321                                    Tiramisu fraise   \n",
       "311434  3256220267762                              Tuiles saveur citrons   \n",
       "277256  3155700003961                       Huile vierge trio biologique   \n",
       "381331  3412290074499                         Madame Loïk a la betterave   \n",
       "220178       20353742                                    Sopa de legumes   \n",
       "153344  0688267150524              Nature's Promise, Organic Fruit Punch   \n",
       "303340  3250391373604                          2 demi baguettes précuite   \n",
       "238428  2424271049922                                 Osso bucco de veai   \n",
       "205919  0939222500619                                               Tuna   \n",
       "385275  3428274140029                                           Milk'nGO   \n",
       "612761  8002816806410                                           Céréales   \n",
       "44982   0041250642893                           Organic Sloppy Joe Sauce   \n",
       "230014  2209686008098                               Poulet fermier blanc   \n",
       "584508  7610200319234                            Bio Haselnüsse Gemahlen   \n",
       "196313  0857750003511                            Uncured Jalapeno Salami   \n",
       "115320  0086600102801                  Solid White Albacore Premium Tuna   \n",
       "147182  0638102646620                       Marcona Almond & Apricot Bar   \n",
       "443582  3700152400082  Chocolat Bonnat chocolat au lait &quot;sans su...   \n",
       "271795  3101740010056                             Confiture de framboise   \n",
       "150830  0674971524041  Dancing Deer Baking Co, Dessert Bites, Caramel...   \n",
       "22115   0023000438642                                            Popcorn   \n",
       "415112  3560071017521                                 Houmous aux olives   \n",
       "50598   0041380000815                                     Yellow Popcorn   \n",
       "236734       23561861                             Brauner Rohr-Rohzucker   \n",
       "448726  3700593403765                          Velouté légumes du soleil   \n",
       "334419  3267853184418         Biscuits apéritifs sticks et bretzels salé   \n",
       "315976  3256226761233                  Mayonnaise à la moutarde de Dijon   \n",
       "195703  0857037005009                      Scramble, Ranchers Vegetables   \n",
       "321934  3258831446000                                  Moutarde de Dijon   \n",
       "161474  0719283985323                Beef Ravioli In Tomato & Meat Sauce   \n",
       "183739  0820581008765                   Sharp Cracker Cut Cheddar Cheese   \n",
       "278826  3165950216349                                     Les saladieres   \n",
       "95693   0074410278236                                      Soybean Paste   \n",
       "140472    04131832086                                         Cheesecake   \n",
       "596428  7613331466945                                                NaN   \n",
       "533322  5053827144018                      Crunchy Muesli With Chocolate   \n",
       "39984   0039400016380                   Bean Pot, Vegetarian Baked Beans   \n",
       "529266  5021812004616                          Fruity raspberry lemonade   \n",
       "166458  0737094211103                                    Roasted Almonds   \n",
       "229284       22043542                                Cogumelos laminados   \n",
       "165960  0735199552008                           Beef Franks In A Blanket   \n",
       "507414       42183112                   Dextrose Täfelchen Minis Limette   \n",
       "18184   0020685001154        Kettle Cooked Potato Chips, Sweet Red Chili   \n",
       "307899  3250547813190                                  Moutarde de Dijon   \n",
       "\n",
       "                  pnns_groups_1         pnns_groups_2  \\\n",
       "138107                      NaN                   NaN   \n",
       "120717                      NaN                   NaN   \n",
       "409970                      NaN                   NaN   \n",
       "145157                      NaN                   NaN   \n",
       "274717            Sugary snacks                Sweets   \n",
       "88666                       NaN                   NaN   \n",
       "395740                      NaN                   NaN   \n",
       "602802                      NaN                   NaN   \n",
       "644180                      NaN                   NaN   \n",
       "130904                      NaN                   NaN   \n",
       "23594                       NaN                   NaN   \n",
       "664399           Fat and sauces  Dressings and sauces   \n",
       "424452                      NaN                   NaN   \n",
       "230268                      NaN                   NaN   \n",
       "327711  Milk and dairy products       Milk and yogurt   \n",
       "248022                      NaN                   NaN   \n",
       "24185                       NaN                   NaN   \n",
       "377050                      NaN                   NaN   \n",
       "104981                      NaN                   NaN   \n",
       "587837                      NaN                   NaN   \n",
       "16879                       NaN                   NaN   \n",
       "75794                       NaN                   NaN   \n",
       "278857                      NaN                   NaN   \n",
       "259739                      NaN                   NaN   \n",
       "5361                        NaN                   NaN   \n",
       "185457                      NaN                   NaN   \n",
       "434260          Composite foods        One-dish meals   \n",
       "366968           Fat and sauces                  Fats   \n",
       "648640     Cereals and potatoes                 Bread   \n",
       "12078                       NaN                   NaN   \n",
       "360189                      NaN                   NaN   \n",
       "115212                      NaN                   NaN   \n",
       "2408                        NaN                   NaN   \n",
       "419879                      NaN                   NaN   \n",
       "44150                       NaN                   NaN   \n",
       "85898                       NaN                   NaN   \n",
       "296034     Cereals and potatoes               Cereals   \n",
       "581901                      NaN                   NaN   \n",
       "615910           Fat and sauces  Dressings and sauces   \n",
       "478633                      NaN                   NaN   \n",
       "374057                      NaN                   NaN   \n",
       "477674                      NaN                   NaN   \n",
       "644472                      NaN                   NaN   \n",
       "249857                      NaN                   NaN   \n",
       "237684                      NaN                   NaN   \n",
       "391589                      NaN                   NaN   \n",
       "66008                       NaN                   NaN   \n",
       "560741                      NaN                   NaN   \n",
       "237602                      NaN                   NaN   \n",
       "492829                      NaN                   NaN   \n",
       "332389                      NaN                   NaN   \n",
       "372094                      NaN                   NaN   \n",
       "263381                      NaN                   NaN   \n",
       "286483                      NaN                   NaN   \n",
       "455150                      NaN                   NaN   \n",
       "50579                       NaN                   NaN   \n",
       "460214                      NaN                   NaN   \n",
       "311434            Sugary snacks    Biscuits and cakes   \n",
       "277256                      NaN                   NaN   \n",
       "381331                      NaN                   NaN   \n",
       "220178                      NaN                   NaN   \n",
       "153344                      NaN                   NaN   \n",
       "303340                      NaN                   NaN   \n",
       "238428                      NaN                   NaN   \n",
       "205919                      NaN                   NaN   \n",
       "385275                Beverages   Sweetened beverages   \n",
       "612761                      NaN                   NaN   \n",
       "44982                       NaN                   NaN   \n",
       "230014           Fish Meat Eggs                  Meat   \n",
       "584508                      NaN                   NaN   \n",
       "196313                      NaN                   NaN   \n",
       "115320                      NaN                   NaN   \n",
       "147182                      NaN                   NaN   \n",
       "443582            Sugary snacks    Chocolate products   \n",
       "271795                      NaN                   NaN   \n",
       "150830                      NaN                   NaN   \n",
       "22115                       NaN                   NaN   \n",
       "415112                      NaN                   NaN   \n",
       "50598                       NaN                   NaN   \n",
       "236734            Sugary snacks                Sweets   \n",
       "448726                      NaN                   NaN   \n",
       "334419             Salty snacks            Appetizers   \n",
       "315976           Fat and sauces  Dressings and sauces   \n",
       "195703                      NaN                   NaN   \n",
       "321934                      NaN                   NaN   \n",
       "161474                      NaN                   NaN   \n",
       "183739                      NaN                   NaN   \n",
       "278826          Composite foods        One-dish meals   \n",
       "95693                       NaN                   NaN   \n",
       "140472                      NaN                   NaN   \n",
       "596428                      NaN                   NaN   \n",
       "533322                      NaN                   NaN   \n",
       "39984                       NaN                   NaN   \n",
       "529266                      NaN                   NaN   \n",
       "166458                      NaN                   NaN   \n",
       "229284                      NaN                   NaN   \n",
       "165960                      NaN                   NaN   \n",
       "507414                      NaN                   NaN   \n",
       "18184                       NaN                   NaN   \n",
       "307899           Fat and sauces  Dressings and sauces   \n",
       "\n",
       "                            groupeAlim_2                  groupeAlim_2_hat  \\\n",
       "138107                               NaN                     Viande, oeufs   \n",
       "120717                               NaN        Produits gras sucrés salés   \n",
       "409970                               NaN        Produits gras sucrés salés   \n",
       "145157                               NaN                     Viande, oeufs   \n",
       "274717        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "88666                                NaN                Féculents raffinés   \n",
       "395740                               NaN        Produits gras sucrés salés   \n",
       "602802                               NaN        Produits gras sucrés salés   \n",
       "644180                               NaN                Féculents raffinés   \n",
       "130904                               NaN                     Viande, oeufs   \n",
       "23594                                NaN                    Plats préparés   \n",
       "664399         Matières grasses ajoutées         Matières grasses ajoutées   \n",
       "424452                               NaN        Produits gras sucrés salés   \n",
       "230268                               NaN        Produits gras sucrés salés   \n",
       "327711  Produits laitiers (hors fromage)  Produits laitiers (hors fromage)   \n",
       "248022                               NaN                            Fruits   \n",
       "24185                                NaN  Produits laitiers (hors fromage)   \n",
       "377050                               NaN                           Fromage   \n",
       "104981                               NaN                    Plats préparés   \n",
       "587837                               NaN  Produits laitiers (hors fromage)   \n",
       "16879                                NaN        Produits gras sucrés salés   \n",
       "75794                                NaN        Produits gras sucrés salés   \n",
       "278857                               NaN                    Plats préparés   \n",
       "259739                               NaN                     Viande, oeufs   \n",
       "5361                                 NaN        Produits gras sucrés salés   \n",
       "185457                               NaN                     Viande, oeufs   \n",
       "434260                    Plats préparés                    Plats préparés   \n",
       "366968         Matières grasses ajoutées         Matières grasses ajoutées   \n",
       "648640                Féculents raffinés                Féculents raffinés   \n",
       "12078                                NaN                Féculents raffinés   \n",
       "360189                               NaN        Produits gras sucrés salés   \n",
       "115212                               NaN                           Légumes   \n",
       "2408                                 NaN        Produits gras sucrés salés   \n",
       "419879                               NaN  Produits laitiers (hors fromage)   \n",
       "44150                                NaN                           Légumes   \n",
       "85898                                NaN                           Légumes   \n",
       "296034                Féculents raffinés                Féculents raffinés   \n",
       "581901                               NaN         Matières grasses ajoutées   \n",
       "615910         Matières grasses ajoutées         Matières grasses ajoutées   \n",
       "478633                               NaN        Produits gras sucrés salés   \n",
       "374057                               NaN                Féculents raffinés   \n",
       "477674                               NaN        Produits gras sucrés salés   \n",
       "644472                               NaN                     Viande, oeufs   \n",
       "249857                               NaN                           Fromage   \n",
       "237684                               NaN  Produits laitiers (hors fromage)   \n",
       "391589                               NaN                     Viande, oeufs   \n",
       "66008                                NaN        Produits gras sucrés salés   \n",
       "560741                               NaN                Féculents raffinés   \n",
       "237602                               NaN                    Plats préparés   \n",
       "492829                               NaN                     Viande, oeufs   \n",
       "332389                               NaN        Produits gras sucrés salés   \n",
       "372094                               NaN        Produits gras sucrés salés   \n",
       "263381                               NaN                           Poisson   \n",
       "286483                               NaN                           Poisson   \n",
       "455150                               NaN        Produits gras sucrés salés   \n",
       "50579                                NaN        Produits gras sucrés salés   \n",
       "460214                               NaN        Produits gras sucrés salés   \n",
       "311434        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "277256                               NaN         Matières grasses ajoutées   \n",
       "381331                               NaN                           Fromage   \n",
       "220178                               NaN                           Légumes   \n",
       "153344                               NaN        Produits gras sucrés salés   \n",
       "303340                               NaN                Féculents raffinés   \n",
       "238428                               NaN                    Plats préparés   \n",
       "205919                               NaN                           Poisson   \n",
       "385275        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "612761                               NaN            Féculents non raffinés   \n",
       "44982                                NaN         Matières grasses ajoutées   \n",
       "230014                     Viande, oeufs                     Viande, oeufs   \n",
       "584508                               NaN                            Fruits   \n",
       "196313                               NaN                     Viande, oeufs   \n",
       "115320                               NaN                           Poisson   \n",
       "147182                               NaN        Produits gras sucrés salés   \n",
       "443582        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "271795                               NaN        Produits gras sucrés salés   \n",
       "150830                               NaN        Produits gras sucrés salés   \n",
       "22115                                NaN        Produits gras sucrés salés   \n",
       "415112                               NaN                           Poisson   \n",
       "50598                                NaN                Féculents raffinés   \n",
       "236734        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "448726                               NaN        Produits gras sucrés salés   \n",
       "334419        Produits gras sucrés salés        Produits gras sucrés salés   \n",
       "315976         Matières grasses ajoutées         Matières grasses ajoutées   \n",
       "195703                               NaN                    Plats préparés   \n",
       "321934                               NaN         Matières grasses ajoutées   \n",
       "161474                               NaN                    Plats préparés   \n",
       "183739                               NaN                           Fromage   \n",
       "278826                    Plats préparés                    Plats préparés   \n",
       "95693                                NaN                           Légumes   \n",
       "140472                               NaN        Produits gras sucrés salés   \n",
       "596428                               NaN        Produits gras sucrés salés   \n",
       "533322                               NaN            Féculents non raffinés   \n",
       "39984                                NaN                           Légumes   \n",
       "529266                               NaN        Produits gras sucrés salés   \n",
       "166458                               NaN        Produits gras sucrés salés   \n",
       "229284                               NaN                           Légumes   \n",
       "165960                               NaN                    Plats préparés   \n",
       "507414                               NaN        Produits gras sucrés salés   \n",
       "18184                                NaN        Produits gras sucrés salés   \n",
       "307899         Matières grasses ajoutées         Matières grasses ajoutées   \n",
       "\n",
       "                               foodgroup  \n",
       "138107                     Viande, oeufs  \n",
       "120717        Produits gras sucrés salés  \n",
       "409970        Produits gras sucrés salés  \n",
       "145157                     Viande, oeufs  \n",
       "274717        Produits gras sucrés salés  \n",
       "88666                 Féculents raffinés  \n",
       "395740        Produits gras sucrés salés  \n",
       "602802        Produits gras sucrés salés  \n",
       "644180                Féculents raffinés  \n",
       "130904                     Viande, oeufs  \n",
       "23594                     Plats préparés  \n",
       "664399         Matières grasses ajoutées  \n",
       "424452        Produits gras sucrés salés  \n",
       "230268        Produits gras sucrés salés  \n",
       "327711  Produits laitiers (hors fromage)  \n",
       "248022                            Fruits  \n",
       "24185   Produits laitiers (hors fromage)  \n",
       "377050                           Fromage  \n",
       "104981                    Plats préparés  \n",
       "587837  Produits laitiers (hors fromage)  \n",
       "16879         Produits gras sucrés salés  \n",
       "75794         Produits gras sucrés salés  \n",
       "278857                    Plats préparés  \n",
       "259739                     Viande, oeufs  \n",
       "5361          Produits gras sucrés salés  \n",
       "185457                     Viande, oeufs  \n",
       "434260                    Plats préparés  \n",
       "366968         Matières grasses ajoutées  \n",
       "648640                Féculents raffinés  \n",
       "12078                 Féculents raffinés  \n",
       "360189        Produits gras sucrés salés  \n",
       "115212                           Légumes  \n",
       "2408          Produits gras sucrés salés  \n",
       "419879  Produits laitiers (hors fromage)  \n",
       "44150                            Légumes  \n",
       "85898                            Légumes  \n",
       "296034                Féculents raffinés  \n",
       "581901         Matières grasses ajoutées  \n",
       "615910         Matières grasses ajoutées  \n",
       "478633        Produits gras sucrés salés  \n",
       "374057                Féculents raffinés  \n",
       "477674        Produits gras sucrés salés  \n",
       "644472                     Viande, oeufs  \n",
       "249857                           Fromage  \n",
       "237684  Produits laitiers (hors fromage)  \n",
       "391589                     Viande, oeufs  \n",
       "66008         Produits gras sucrés salés  \n",
       "560741                Féculents raffinés  \n",
       "237602                    Plats préparés  \n",
       "492829                     Viande, oeufs  \n",
       "332389        Produits gras sucrés salés  \n",
       "372094        Produits gras sucrés salés  \n",
       "263381                           Poisson  \n",
       "286483                           Poisson  \n",
       "455150        Produits gras sucrés salés  \n",
       "50579         Produits gras sucrés salés  \n",
       "460214        Produits gras sucrés salés  \n",
       "311434        Produits gras sucrés salés  \n",
       "277256         Matières grasses ajoutées  \n",
       "381331                           Fromage  \n",
       "220178                           Légumes  \n",
       "153344        Produits gras sucrés salés  \n",
       "303340                Féculents raffinés  \n",
       "238428                    Plats préparés  \n",
       "205919                           Poisson  \n",
       "385275        Produits gras sucrés salés  \n",
       "612761            Féculents non raffinés  \n",
       "44982          Matières grasses ajoutées  \n",
       "230014                     Viande, oeufs  \n",
       "584508                            Fruits  \n",
       "196313                     Viande, oeufs  \n",
       "115320                           Poisson  \n",
       "147182        Produits gras sucrés salés  \n",
       "443582        Produits gras sucrés salés  \n",
       "271795        Produits gras sucrés salés  \n",
       "150830        Produits gras sucrés salés  \n",
       "22115         Produits gras sucrés salés  \n",
       "415112                           Poisson  \n",
       "50598                 Féculents raffinés  \n",
       "236734        Produits gras sucrés salés  \n",
       "448726        Produits gras sucrés salés  \n",
       "334419        Produits gras sucrés salés  \n",
       "315976         Matières grasses ajoutées  \n",
       "195703                    Plats préparés  \n",
       "321934         Matières grasses ajoutées  \n",
       "161474                    Plats préparés  \n",
       "183739                           Fromage  \n",
       "278826                    Plats préparés  \n",
       "95693                            Légumes  \n",
       "140472        Produits gras sucrés salés  \n",
       "596428        Produits gras sucrés salés  \n",
       "533322            Féculents non raffinés  \n",
       "39984                            Légumes  \n",
       "529266        Produits gras sucrés salés  \n",
       "166458        Produits gras sucrés salés  \n",
       "229284                           Légumes  \n",
       "165960                    Plats préparés  \n",
       "507414        Produits gras sucrés salés  \n",
       "18184         Produits gras sucrés salés  \n",
       "307899         Matières grasses ajoutées  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openfoodfacts_foodgroup_nutrients[['EAN', 'product_name', 'pnns_groups_1', 'pnns_groups_2', 'groupeAlim_2', level_groupe + '_hat', 'foodgroup']].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "openfoodfacts_foodgroup_nutrients.to_csv(\"../../data/openfoodfacts_\" + level_groupe +\".csv\",\n",
    "                                         sep = ';', encoding = 'UTF-8', index = False,\n",
    "                                         columns = [\"product_name\", \"EAN\", \"foodgroup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
